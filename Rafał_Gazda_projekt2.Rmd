---
title: "Sprawozdanie"
author: "RafaĹ‚ Gazda"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
library(e1071)
library(car)
library(lawstat) 
library(aod)
library(lmtest)
library(randtests)
library(strucchange)
  MyData <- read.csv(file="C:/Users/Gazi/Desktop/Matematyka ekonomiczna/Projekt2/DaneZ2.csv", header=TRUE, sep=",")
  MyData
```

## Opis danych

Zbiór zawiera 7 zmiennych- jedną objaśnianą (bwght- waga dziecka po urodzeniu w gramach), oraz 6 zmiennych objaśniających:npvis (liczba wizyt ginekologicznych przed porodem), fage (wiek ojca w latach), cigs (średnia dzienna liczba palonych papierosów przez matkę), drink (średnia tygodniowa liczba drików alkoholowych spożywanych przez matkę), pree (zmienna binarna- 1 jeżeli dziecko jest wcześniakiem), male (zmienna binarna, 1 jeżeli dziecko jest chłopcem).

## Podstawowe statystyki

```{r}
MyData <- na.omit(MyData)

stats <-  lapply( MyData , function(x) rbind( mean = mean(x) ,
                                         sd = sd(x) ,
                                         median = median(x) ,
                                         minimum = min(x) ,
                                         maximum = max(x) ,
                                         kurtosis = kurtosis(x),
                                         skewness = skewness(x),
                                         coeff = sd(x)/mean(x) * 100
                                         ))

data.frame(stats)
```
Na podstawie podstawowych statystyk można zauważyć, że brakuje nam niektórych danych oraz wartości są różnej skali, widać to szczególnie przy współczynniku zmienności, który dla niektórych danych jest bardzo wysoki. 
Aby poradzić sobie z brakującymi danymi, usunę wiersze, w których się one znajdują. W tym przypadku usunięcie wierszy nie jest złą metodą, ponieważ posiadamy dużo obserwacji. W innych przypadkach można użyć procedur takich jak Amelia 2, Mice, mitools. Dla wszystkich zmiennych oprócz _male_ kurtoza jest większa od zera, co oznacz, że rozkład prawdopodobieństwo jest leptokurtyczna (wartości cechy bardziej skoncentrowane niż przy rozkładzie normalnym). Zmienne _bwght_ i _male_ mają rozkład lewostronnej asymetrii, a reszta zmiennych ma rozkład prawostronnej asymetrii.

Do rozwiązania problemu ze skalą danych użyję standaryzacji.

```{r}
  MyData <- as.data.frame(scale(MyData))
```

## Model MNK

```{r}
  MNK_liniowy <- lm(formula = bwght ~ 1 + npvis + fage + cigs + drink + pree + male, data = MyData)
```
Po stworzeniu modelu należy się zastanowić, które ze zmiennych są statystycznie istotnie do tego zostanie użyty test t-studenta i metoda krokowa wsteczna. Jednak aby móc się opierać na statystyce t-studenta, muszę najpierw przeprowadzić test normalności reszt Shapiro Wilka.

```{r}
resi <- MNK_liniowy$residuals
shapiro.test(resi)
```

Hipoteza zerowa tego testu jest na tyle duża, że nie mamy podstaw do odrzucenia hipotezy H0, która zakłada normalność reszt rozkładu, a co za tym idzie możemy się opierać na statystyce t-studenta.

```{r}
  summary(MNK_liniowy)
```

Na podstawie metody krokowo wstecznej możemy odrzucić zmienną drink, ponieważ nie jest ona istotna statystycznie.

```{r}
  MNK_liniowy <- lm(formula = bwght ~ 1 + npvis + fage + cigs + pree + male, data = MyData)
  resi <- MNK_liniowy$residuals
  shapiro.test(resi)
  summary(MNK_liniowy)
```

Dla 95% poziomu istotności reszta zmiennych jest isotna, więc zostawiam model w takiej postaci. Ostateczny model nie opisuje zadowalająco zjawiska, ponieważ _R-kwadrat_ wynosi około 0.2. 

## Przekształcenie modelu

Przed przejściem do dalszej częsci projektu muszę odpowiedzieć czy ta postać modelu jest prawidłowa. Zaczynam od sprawdzenia czy liniowa postać modelu jest optymalna z wykorzystaniem testu _RESET Ramsey'a_, który porównuje ją do zależności kwadratowej i sześciennej.

```{r}
resettest(MNK_liniowy)
```

Taka wartość _p-value_ nie pozwala na odrzucenie hipotezy zerowej mówiącej o tym, że ta postać liniowa modelu jest najlepsza z trzech porównywanych. Wskazywałoby to na fakt, że ta postać modelu jest najoptymalniejsza. Aby się upewnić zastosujemy test _serii Walda-Wolfowitza_.

```{r}
runs.test(resi)
```

Tutaj również _p-value_ nie pozwala na odrzucenie hipotezy zerowej, czyli można uznać, że ta postać modelu jest optymalna.


## Koincydentność modelu
```{r}
summary(MNK_liniowy)
cor(MyData, method = c("pearson"))
```
  Model jest koincydentny, ponieważ znaki odpowiednich wartości w korelacji pearsona są takie same jak znaki przy odpowiednich parametrach modelu.

## Współliniowość modelu
```{r}
vif(MNK_liniowy)
```
Zmienne nie są współliniowe, ponieważ wartość testu w każdym przypadku jest mniejsza niż 10.

## Test Chowa
Następnie stosuje test _Chow'a_ by sprawdzić stabilność postaci modelu (hipoteza zerowa tego testu możee być interpretowana jako stabilność postaci modelu)

```{r}
sctest(bwght ~ npvis + fage + cigs + pree + male, type="Chow",data=MyData)
```
W tym przypadku wartść _p-value_ dla normalnie wykorzystywanych poziomów istotnoĹ›ci (0.9, 0.95, 0.99) nie daje podstaw do odrzucenia _H0_, a zatem możemy mówić tutaj o stabilnej postaci modelu. Następnie zbadam występowanie zjawiska autokorelacjii wykorzystując test _Durbina-Watsona_.

## Test Durbina-Watsona
```{r}
dwtest(MNK_liniowy)
```

W tym przypadku również wartość _p-value_ jest na tyle duża by nie dać podstaw do odrzucenia _H0_, która w tym przypadku mówi o braku zjawiska autokorelacji, a zatem o niezależności składnika losowego modelu.

## Test Goldfielda-Quandta
Następnym przeprowadzonym przeze mnie testem jest test _Goldfielda-Quandta_ pozwalający sprawdzić czy w modelu występuje zjawisko hetero/homoskedastyczności.

```{r}
gqtest(MNK_liniowy)
```

Tutaj również _p-value_ jest na tyle duże i nie ma podstaw do odrzucenia hipotezy _H0_, która mówi o stałoći wariancji składnika losowego.

## Test serii
H0: dobór jednostek do próby jest losowy; model jest liniowy.
H1: dobór jednostek do próby nie jest losowy; model jest nieliniowy.

```{r}
runs.test(MyData$bwght)
```
Ponieważ p-value jest mniejsze od 0.05 to oznacza, że nie ma podstaw do odrzucenia hipotezy H0.

## Test istotności zmiennych
```{r, echo=FALSE}
wald.test(b=coef(object=MNK_liniowy), Sigma=vcov(object=MNK_liniowy), Terms=2)
```
Ponieważ p-value jest mniejsze od 0.05 to oznacz, że nie podstaw do odrzucenia H0, czyli łącznie zmienne są istotne.

## Interpretacja parametrów
```{r, echo=FALSE}
  summary(MNK_liniowy)
```

 W ostatecznym zestanderyzowanym modelu wszystkie zmienne są istotne.
  Zmienne, których wzrost wpływa na powiększenie masy ciała dziecka to:
  - npvis (liczba wizyt ginekologicznych)
  - fage (wiek ojca)
  - male (płeć, w tym przypadku płeć męska wpływa na wzrost wagi)
  Zmienne, których wzrost wpływa na zmniejszenie się masy ciała dziecka to:
  - cigs (średnia dzienna liczba palonych papierosów przez matkę)
  - pree (zmienna binarna- 1 jeżeli dziecko jest wcześniakiem)
  
  przy założeniu ceteris paribus o reszcie parametrów stałych.
  
  Zmienna, która ma największy wpływa na masę dziecka to `pree`. A zmienna, która ma najmniejszy wpływa na masę dziecka to `fage`.
 
